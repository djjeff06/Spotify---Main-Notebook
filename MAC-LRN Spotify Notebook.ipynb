{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Basic Flow</b>\n",
    "- Background of task and data\n",
    "- Summary of technique used\n",
    "- Simple data analysis (show of original data features)\n",
    "- Preprocessing\n",
    "- Feature Extraction (no feature extraction since the features are already given from the second data set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Background and Related Works</b>\n",
    "\n",
    "In recent years, music revenue in the United States has seen substantial growth. In 2017, revenues from recorded music in the United States increased 16.5% at estimated retail value to $8.7 billion, continuing the growth from the previous year. Paid subscriptions from streaming services like Spotify and Apple Music were the biggest growth driver for the music industry in 2017. The revenues from streaming platforms made up 65% of total industry revenues. [1] Online streaming can now be seen as \n",
    "the new norm for accessing and distributing music. Therefore, having a fundamental understanding of what makes a song popular \n",
    "has major implications to musicians and record labels that thrive on stream count and song popularity. \n",
    "\n",
    "The ability to make accurate predictions of song popularity could be achieved through the use of machine learning techniques. \n",
    "\n",
    "Pham, Kyauk and Park used both acoustic features and metadata to create both classification and predictive models, to determine \n",
    "if whether or not the song is popular or in the case of the latter, predict the popularity score. Upon applying SVMs, neural \n",
    "networks and logistic regression for classification, SVM (Gaussian kernel) yielded the highest F1 score. As for regression, \n",
    "they fitted the models using a standard multiple linear regression, and applied feature selection methods to achieve the best \n",
    "coefficient estimates for regression.it was Logistic Lasso regression that yielded the smallest test error. The research \n",
    "concluded that the acoustic features aren’t nearly as predicative as the metadata features. A likely reason for this is that \n",
    "there is a lot of variation in acoustic features within a single song that make it difficult to extract metrics that represent \n",
    "an entire song.[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Objective</b>\n",
    "\n",
    "Determine the popularity of a song based on the given audio features with a value of 1 for popular and 0 for unpopular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Machine Learning Techniques</b>\n",
    "\n",
    "A. Classification:<br>\n",
    "1. Naive Bayes<br>\n",
    "2. SVM<br>\n",
    "3. Decision Tree<br>\n",
    "4. Logistic Regression<br>\n",
    "5. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Description of the Data</b>\n",
    "\n",
    "This research uses data from two Kaggle datasets, namely Spotify’s Worldwide Daily Song Ranking [1] and Top Spotify Tracks of 2017 [2]. The former is a collection of Spotify’s most streamed songs in different regions across the world for each day of 2017. Each row contains a ranking position on a specific day and region. There are roughly 200 entries per day for each region, however be aware that some of Spotify's data was missing in very few occasions. Due to this, the researchers have only focused on the streams (stream count) column for each entry. The latter is a collection of the audio features of the songs found in the Top Spotify Tracks of 2017 playlist in Spotify. Aside from the song title, artist and song url, each song is given values for 13 audio features listed and defined by Spotify API below.\n",
    "<style>\n",
    "table, th, td {\n",
    "    border: 1px solid black;\n",
    "    border-collapse: collapse;\n",
    "    padding: 15px;\n",
    "    text-align: left;\n",
    "}\n",
    "</style>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Feature</th>\n",
    "    <th>Description</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Danceability</td>\n",
    "    <td>Describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Energy</td>\n",
    "    <td>A measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Key</td>\n",
    "    <td>The key the track is in. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Loudness</td>\n",
    "    <td>The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Mode</td>\n",
    "    <td>Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Speechiness</td>\n",
    "    <td>Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Acousticness</td>\n",
    "    <td>A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Instrumentalness</td>\n",
    "    <td>Predicts whether a track contains no vocals. \"Ooh\" and \"aah\" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \"vocal\". The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Liveliness</td>\n",
    "    <td>Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Valence</td>\n",
    "    <td>A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Tempo</td>\n",
    "    <td>The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Duration</td>\n",
    "    <td>The duration of the track in milliseconds.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Time Signature</td>\n",
    "    <td>An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shown below is the hard-coded table (since file size is extremely large) of the first 5 rows of the Spotify’s Worldwide Daily Song Ranking dataset. For reference, you can view the entire dataset here: https://www.kaggle.com/edumucelli/spotifys-worldwide-daily-song-ranking/data\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Position</th>\n",
    "    <th>Track Name</th>\n",
    "    <th>Artist</th>\n",
    "    <th>Streams</th> \n",
    "    <th>URL</th>\n",
    "    <th>Date</th>\n",
    "    <th>Region</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Reggaetón Lento (Bailemos)</td>\n",
    "    <td>CNCO</td>\n",
    "    <td>19272</td> \n",
    "    <td>https://open.spotify.com/track/3AEZUABDXNtecAOSC1qTfo</td>\n",
    "    <td>2017-01-01</td>\n",
    "    <td>ec</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td>Chantaje</td>\n",
    "    <td>Shakira</td>\n",
    "    <td>19270</td> \n",
    "    <td>https://open.spotify.com/track/6mICuAdrwEjh6Y6lroV2Kg</td>\n",
    "    <td>2017-01-01</td>\n",
    "    <td>ec</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td>Otra Vez (feat. J Balvin)</td>\n",
    "    <td>Zion & Lennox</td>\n",
    "    <td>15761</td> \n",
    "    <td>https://open.spotify.com/track/3QwBODjSEzelZyVjxPOHdq</td>\n",
    "    <td>2017-01-01</td>\n",
    "    <td>ec</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>4</td>\n",
    "    <td>Vente Pa' Ca</td>\n",
    "    <td>Ricky Martin</td>\n",
    "    <td>14954</td> \n",
    "    <td>https://open.spotify.com/track/7DM4BPaS7uofFul3ywMe46</td>\n",
    "    <td>2017-01-01</td>\n",
    "    <td>ec</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5</td>\n",
    "    <td>Safari</td>\n",
    "    <td>J Balvin</td>\n",
    "    <td>14269</td> \n",
    "    <td>https://open.spotify.com/track/6rQSrBHf7HlZjtcMZ4S4bO</td>\n",
    "    <td>2017-01-01</td>\n",
    "    <td>ec</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "# Fix the seed of the random number \n",
    "# generator so that your results will match ours\n",
    "np.random.seed(1)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shown below is the first 5 rows of the Top Spotify Tracks of 2017 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7qiZfU4dY1lWllzX7mPBI</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.931</td>\n",
       "      <td>95.977</td>\n",
       "      <td>233713.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5CtI0qwDJkDQGwXD1H1cL</td>\n",
       "      <td>Despacito - Remix</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.815</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>0.813</td>\n",
       "      <td>88.931</td>\n",
       "      <td>228827.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4aWmUDTfIPGksMNLV2rQP</td>\n",
       "      <td>Despacito (Featuring Daddy Yankee)</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.786</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.846</td>\n",
       "      <td>177.833</td>\n",
       "      <td>228200.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6RUKPb4LETWmmr3iAEQkt</td>\n",
       "      <td>Something Just Like This</td>\n",
       "      <td>The Chainsmokers</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.635</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-6.769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>0.446</td>\n",
       "      <td>103.019</td>\n",
       "      <td>247160.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3DXncPQOG4VBw3QHh3S81</td>\n",
       "      <td>I'm the One</td>\n",
       "      <td>DJ Khaled</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.668</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-4.284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>0.811</td>\n",
       "      <td>80.924</td>\n",
       "      <td>288600.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                name  \\\n",
       "0  7qiZfU4dY1lWllzX7mPBI                        Shape of You   \n",
       "1  5CtI0qwDJkDQGwXD1H1cL                   Despacito - Remix   \n",
       "2  4aWmUDTfIPGksMNLV2rQP  Despacito (Featuring Daddy Yankee)   \n",
       "3  6RUKPb4LETWmmr3iAEQkt            Something Just Like This   \n",
       "4  3DXncPQOG4VBw3QHh3S81                         I'm the One   \n",
       "\n",
       "            artists  danceability  energy   key  loudness  mode  speechiness  \\\n",
       "0        Ed Sheeran         0.825   0.652   1.0    -3.183   0.0       0.0802   \n",
       "1        Luis Fonsi         0.694   0.815   2.0    -4.328   1.0       0.1200   \n",
       "2        Luis Fonsi         0.660   0.786   2.0    -4.757   1.0       0.1700   \n",
       "3  The Chainsmokers         0.617   0.635  11.0    -6.769   0.0       0.0317   \n",
       "4         DJ Khaled         0.609   0.668   7.0    -4.284   1.0       0.0367   \n",
       "\n",
       "   acousticness  instrumentalness  liveness  valence    tempo  duration_ms  \\\n",
       "0        0.5810          0.000000    0.0931    0.931   95.977     233713.0   \n",
       "1        0.2290          0.000000    0.0924    0.813   88.931     228827.0   \n",
       "2        0.2090          0.000000    0.1120    0.846  177.833     228200.0   \n",
       "3        0.0498          0.000014    0.1640    0.446  103.019     247160.0   \n",
       "4        0.0552          0.000000    0.1670    0.811   80.924     288600.0   \n",
       "\n",
       "   time_signature  \n",
       "0             4.0  \n",
       "1             4.0  \n",
       "2             4.0  \n",
       "3             4.0  \n",
       "4             4.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify = pd.read_csv('featuresdf.csv')\n",
    "spotify.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exploratory Data Analysis</b>\n",
    "\n",
    "Create a distribution plot for the values for each audio feature.<br>\n",
    "Create a feature correlation heat map.<br>\n",
    "See the following examples:<br>\n",
    "https://medium.com/mlreview/spotify-analyzing-and-predicting-songs-58827a0fa42b <br>\n",
    "https://www.kaggle.com/cihanoklap/top-songs-on-spotify-what-makes-them-popular <br>\n",
    "https://www.kaggle.com/nadintamer/what-makes-top-spotify-songs-popular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data Preprocessing</b>\n",
    "\n",
    "Since the research checks the association between the song’s stream count and the song’s features, the researchers have to make sure that the song entry exists in both datasets. The researchers mapped the 100 songs from the Top Spotify Tracks dataset to the entries in the Spotify’s Worldwide Daily Song Ranking dataset and pulled entries with matching song titles. The 256718 entries will serve as the researchers’ working dataset. The dataset would contain duplicate entries, since songs could be on the top 200 in a span of several days in different regions. The researchers get the total stream count per song for the whole year.<br><br>\n",
    "With stream count as the metric of popularity, songs with a stream count higher than mean would be considered as popular (1) and the rest would be labeled as unpopular (0). The song name, stream count and other columns are no longer relevant after preprocessing thus they are removed.\n",
    "\n",
    "Shown below is the final product of the data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveliness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.581000</td>\n",
       "      <td>0.825</td>\n",
       "      <td>233713</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>-3.183</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>95.977</td>\n",
       "      <td>0.931</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.694</td>\n",
       "      <td>228827</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>-4.328</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>88.931</td>\n",
       "      <td>0.813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.904</td>\n",
       "      <td>177000</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0976</td>\n",
       "      <td>-6.842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>150.020</td>\n",
       "      <td>0.400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.726</td>\n",
       "      <td>233902</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.01010</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>-5.043</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>97.985</td>\n",
       "      <td>0.733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002640</td>\n",
       "      <td>0.732</td>\n",
       "      <td>182707</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>-6.366</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2310</td>\n",
       "      <td>155.096</td>\n",
       "      <td>0.401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration  energy  instrumentalness  key  \\\n",
       "0      0.581000         0.825    233713   0.652           0.00000    1   \n",
       "1      0.229000         0.694    228827   0.815           0.00000    2   \n",
       "2      0.000259         0.904    177000   0.611           0.00002    1   \n",
       "3      0.029300         0.726    233902   0.769           0.01010    6   \n",
       "4      0.002640         0.732    182707   0.750           0.00000   11   \n",
       "\n",
       "   liveliness  loudness  mode  speechiness    tempo  valence  popular  \n",
       "0      0.0931    -3.183     0       0.0802   95.977    0.931        1  \n",
       "1      0.0924    -4.328     1       0.1200   88.931    0.813        1  \n",
       "2      0.0976    -6.842     0       0.0888  150.020    0.400        1  \n",
       "3      0.1040    -5.043     1       0.1230   97.985    0.733        1  \n",
       "4      0.1090    -6.366     0       0.2310  155.096    0.401        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify = pd.read_csv('spotify_dataset.csv')\n",
    "spotify.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Feature Selection</b>\n",
    "\n",
    "Choose one of the following:<br>\n",
    "1) Forward Stepwise Selection - Forward selection greedily chooses the best combination of features by starting with an empty subset of features, then incrementally adding a feature to the model that was selected through evaluation of the feature subset through cross-validation. This step is repeated until the generalization error is minimized and the best subset of features is reported.<br>\n",
    "2) Backward Stepwise Selection - Backward stepwise selection works similarly to forward stepwise selection; however, instead of starting with an empty subset of features, it begins by evaluating the use of all features and incrementally removes features until the model is optimized.<br>\n",
    "3) Regularization - Regularization is a shrinkage method that regularizes the coefficient estimates by shrinking the coefficients towards zero. Regularization often improves the fit because reducing coefficient estimates can significantly.<br>\n",
    "\n",
    "However, sklearn doesn't have either forward or backward selection algorithm, it does provide recursive feature elimination, which is a greedy feature elimination algorithm similar to sequential backward selection.\n",
    "\n",
    "Recursive feature elimination (RFE) deselects features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coef_ attribute or through a feature_importances_ attribute. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 1, 1, 1, 7, 1, 2, 5, 6, 3, 4, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "spotify = pd.read_csv('spotify_dataset.csv')\n",
    "\n",
    "X = pd.DataFrame.drop(spotify,labels=['popular'],axis=1).as_matrix()\n",
    "y = pd.DataFrame.drop(spotify,labels=['acousticness','duration','danceability','energy','instrumentalness','key','liveliness','loudness','mode','speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "\n",
    "y=np.ravel(y)\n",
    "estimator = DecisionTreeClassifier()\n",
    "selector = RFE(estimator, 5, step=1)\n",
    "selector = selector.fit(X, y)\n",
    "selector.support_ \n",
    "selector.ranking_\n",
    "\n",
    "#duration, danceability, energy, liveliness, tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output above, the indices represented by 1's will be the top five features that will be used, which are duration, danceability, energy, liveliness, and tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Metrics</b>\n",
    "\n",
    "Precision, recall, and F1 score are used to capture how well our model does in the task of classification. Precision measures the portion of examples that were classified as popular that are truly popular while recall measures the portion of examples that are truly popular that our model classified as popular. F1 score acts as the weighted average between these two values. \n",
    "\n",
    "The AUC is a metric used to evaluate the performance of a binary classifier by taking the area under a curve created by plotting TPR vs. FPR at different probability thresholds. The AUC represents the probability that the classifier ranks a random positive example higher than a random negative one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model Training</b>\n",
    "\n",
    "<b> Decision Tree </b><br>\n",
    "Among the different machine learning classification algorithms, we first implement a model for decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we first import the data from csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveliness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.581000</td>\n",
       "      <td>0.825</td>\n",
       "      <td>233713</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>-3.183</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>95.977</td>\n",
       "      <td>0.931</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.694</td>\n",
       "      <td>228827</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>-4.328</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>88.931</td>\n",
       "      <td>0.813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.904</td>\n",
       "      <td>177000</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0976</td>\n",
       "      <td>-6.842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>150.020</td>\n",
       "      <td>0.400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.726</td>\n",
       "      <td>233902</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.01010</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>-5.043</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>97.985</td>\n",
       "      <td>0.733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002640</td>\n",
       "      <td>0.732</td>\n",
       "      <td>182707</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>-6.366</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2310</td>\n",
       "      <td>155.096</td>\n",
       "      <td>0.401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration  energy  instrumentalness  key  \\\n",
       "0      0.581000         0.825    233713   0.652           0.00000    1   \n",
       "1      0.229000         0.694    228827   0.815           0.00000    2   \n",
       "2      0.000259         0.904    177000   0.611           0.00002    1   \n",
       "3      0.029300         0.726    233902   0.769           0.01010    6   \n",
       "4      0.002640         0.732    182707   0.750           0.00000   11   \n",
       "\n",
       "   liveliness  loudness  mode  speechiness    tempo  valence  popular  \n",
       "0      0.0931    -3.183     0       0.0802   95.977    0.931        1  \n",
       "1      0.0924    -4.328     1       0.1200   88.931    0.813        1  \n",
       "2      0.0976    -6.842     0       0.0888  150.020    0.400        1  \n",
       "3      0.1040    -5.043     1       0.1230   97.985    0.733        1  \n",
       "4      0.1090    -6.366     0       0.2310  155.096    0.401        1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify = pd.read_csv('spotify_dataset.csv')\n",
    "spotify[\"popular\"] = pd.Categorical(spotify[\"popular\"]).codes\n",
    "spotify.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we arrange the data into the X and y variables using pandas.DataFrame.drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94, 5)\n",
      "(94, 1)\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame.drop(spotify,labels=['popular','acousticness','instrumentalness','key','loudness','mode','speechiness','valence'],axis=1).as_matrix()\n",
    "y = pd.DataFrame.drop(spotify,labels=['acousticness','duration','danceability','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we separate the data into a train set and a test set to test the accuracy of our model's predictions later on. We then construct our DecisionTreeClassifier model from sklearn and fit our train data in it. Afterward, we make some predictions using the test set and print out the mean of all the accuracies after a total of 1000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y)\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X_train,y_train)\n",
    "    predictions = dtc.predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5414166666666667\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5210084033613445\n"
     ]
    }
   ],
   "source": [
    "print(metrics.roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    }
   ],
   "source": [
    "print(metrics.f1_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "print(metrics.recall_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Naive Bayes</b>\n",
    "\n",
    "<b>Gaussian Distribution</b><br>\n",
    "Here we use the same X and y from the one we processed in Decision Trees above. We will use GaussianNB since our feature values are continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y)\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train,y_train)\n",
    "    predictions = gnb.predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5635416666666666\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(metrics.roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375\n"
     ]
    }
   ],
   "source": [
    "print(metrics.f1_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(metrics.recall_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted labels for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpopular: 36.0\n",
      "Popular: 34.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Unpopular:\",gnb.class_count_[0])\n",
    "print(\"Popular:\",gnb.class_count_[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The priors the model used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpopular: 0.5142857142857142\n",
      "Popular: 0.4857142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"Unpopular:\",gnb.class_prior_[0])\n",
    "print(\"Popular:\",gnb.class_prior_[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Neural Networks</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame.drop(spotify,labels=['popular','acousticness','instrumentalness','key','loudness','mode','speechiness','valence'],axis=1).as_matrix()\n",
    "y = pd.DataFrame.drop(spotify,labels=['acousticness','duration','danceability','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "y = np.ravel(y)\n",
    "data = X\n",
    "target = y\n",
    "N, M  = data.shape\n",
    "X = np.ones((N, M + 1))\n",
    "X[:, 1:] = data\n",
    "\n",
    "# Convert into one-hot vectors\n",
    "num_labels = len(np.unique(target))\n",
    "Y = np.eye(num_labels)[target] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (62, 6)\n",
      "y_train shape : (62, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape :\", X_train.shape)\n",
    "print(\"y_train shape :\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we shall model the neural network using softmax cross entropy with logits for computing the score, loss, and probability. Below, we test out different optimizer parameter to see which optimizer yields better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_instances = 100 # number of instances (N)\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def init_weights(n_input, n_hidden, n_output):\n",
    "\n",
    "    w1 = tf.random_normal(np.shape(np.zeros((n_input, n_hidden))),stddev=0.1,seed=RANDOM_SEED)\n",
    "    w2 = tf.random_normal(np.shape(np.zeros((n_hidden,n_output))),stddev=0.1,seed=RANDOM_SEED)\n",
    "\n",
    "    weights = {\n",
    "        'w1': tf.Variable(w1),\n",
    "        'w2': tf.Variable(w2)\n",
    "    }\n",
    "\n",
    "    return weights\n",
    "\n",
    "def do_forwardprop(X, W1, W2):\n",
    "\n",
    "    z1 = tf.matmul(X,W1)     # 1st layer score\n",
    "    a1 = tf.nn.sigmoid(z1)     # 1st layer activation\n",
    "    z2 = tf.matmul(z1,W2)      # 2nd layer score\n",
    "    a2 = tf.nn.sigmoid(z2)     # 2nd layer activation\n",
    "\n",
    "    return a2, z2\n",
    "\n",
    "def main(optimizer_fn):\n",
    "\n",
    "    loss_over_time = np.array([])\n",
    "\n",
    "    n_input  = 6      # Number of input nodes: # features and 1 bias\n",
    "    n_hidden = 10      # Number of hidden nodes\n",
    "    n_output = 2      # Number of outputs \n",
    "\n",
    "    weights = init_weights(n_input, n_hidden, n_output)\n",
    "\n",
    "    X = tf.placeholder(\"float32\", shape=[None, n_input])      # 1st parameter is None because to accommodate multiple instanced\n",
    "    y = tf.placeholder(\"float32\", shape=[None, n_output])      # 1st parameter is None because to accommodate multiple instanced\n",
    "    \n",
    "    a2, z2 = do_forwardprop(X, weights['w1'], weights['w2'])\n",
    "\n",
    "    predict  = tf.argmax(a2, axis=1)\n",
    "\n",
    "    loss      = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=z2))\n",
    "    \n",
    "    if optimizer_fn == \"momentum\":\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate=1e-3, momentum=0.9).minimize(loss) \n",
    "    elif optimizer_fn == \"rmsprop\":\n",
    "        optimizer = tf.train.RMSPropOptimizer(learning_rate=1e-3).minimize(loss) \n",
    "    elif optimizer_fn == \"adam\":\n",
    "        optimizer = tf.train.AdamOptimizer().minimize(loss) \n",
    "    elif optimizer_fn == \"gd\":\n",
    "        optimizer = tf.train.GradientDescentOptimizer().minimize(loss)\n",
    "\n",
    "    session = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    session.run(init)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        for i in range(len(X_train)):\n",
    "            _, l = session.run([optimizer, loss], feed_dict={X: X_train[i: i + 1], y: y_train[i: i + 1]})\n",
    "\n",
    "        loss_over_time = np.append(loss_over_time, l)\n",
    "        \n",
    "        train_accuracy = np.mean(np.argmax(y_train, axis=1) == session.run(predict, feed_dict={X: X_train, y: y_train}))\n",
    "        test_accuracy  = np.mean(np.argmax(y_test, axis=1) == session.run(predict, feed_dict={X: X_test, y: y_test}))\n",
    "        print(\"Epoch = %d, train accuracy = %.2f%%, test accuracy = %.2f%%\"\n",
    "              % (epoch + 1, 100. * train_accuracy, 100. * test_accuracy))\n",
    "\n",
    "    weights = session.run(weights)\n",
    "    session.close()\n",
    "    \n",
    "    return loss_over_time, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 2, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 3, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 4, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 5, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 6, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 7, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 8, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 9, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 10, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 11, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 12, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 13, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 14, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 15, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 16, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 17, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 18, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 19, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 20, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 21, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 22, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 23, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 24, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 25, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 26, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 27, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 28, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 29, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 30, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 31, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 32, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 33, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 34, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 35, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 36, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 37, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 38, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 39, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 40, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 41, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 42, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 43, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 44, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 45, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 46, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 47, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 48, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 49, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 50, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 51, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 52, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 53, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 54, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 55, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 56, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 57, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 58, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 59, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 60, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 61, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 62, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 63, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 64, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 65, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 66, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 67, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 68, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 69, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 70, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 71, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 72, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 73, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 74, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 75, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 76, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 77, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 78, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 79, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 80, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 81, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 82, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 83, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 84, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 85, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 86, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 87, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 88, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 89, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 90, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 91, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 92, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 93, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 94, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 95, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 96, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 97, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 98, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 99, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 100, train accuracy = 58.06%, test accuracy = 46.88%\n"
     ]
    }
   ],
   "source": [
    "momentum_loss, momentum_weight = main(\"momentum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 2, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 3, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 4, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 5, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 6, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 7, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 8, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 9, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 10, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 11, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 12, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 13, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 14, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 15, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 16, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 17, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 18, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 19, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 20, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 21, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 22, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 23, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 24, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 25, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 26, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 27, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 28, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 29, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 30, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 31, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 32, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 33, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 34, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 35, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 36, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 37, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 38, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 39, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 40, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 41, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 42, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 43, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 44, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 45, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 46, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 47, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 48, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 49, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 50, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 51, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 52, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 53, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 54, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 55, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 56, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 57, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 58, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 59, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 60, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 61, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 62, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 63, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 64, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 65, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 66, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 67, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 68, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 69, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 70, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 71, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 72, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 73, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 74, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 75, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 76, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 77, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 78, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 79, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 80, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 81, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 82, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 83, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 84, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 85, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 86, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 87, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 88, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 89, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 90, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 91, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 92, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 93, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 94, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 95, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 96, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 97, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 98, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 99, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 100, train accuracy = 58.06%, test accuracy = 46.88%\n"
     ]
    }
   ],
   "source": [
    "rmsprop_loss, rmsprop_weight = main(\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 2, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 3, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 4, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 5, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 6, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 7, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 8, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 9, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 10, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 11, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 12, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 13, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 14, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 15, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 16, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 17, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 18, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 19, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 20, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 21, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 22, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 23, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 24, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 25, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 26, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 27, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 28, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 29, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 30, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 31, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 32, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 33, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 34, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 35, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 36, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 37, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 38, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 39, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 40, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 41, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 42, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 43, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 44, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 45, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 46, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 47, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 48, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 49, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 50, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 51, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 52, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 53, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 54, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 55, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 56, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 57, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 58, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 59, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 60, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 61, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 62, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 63, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 64, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 65, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 66, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 67, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 68, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 69, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 70, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 71, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 72, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 73, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 74, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 75, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 76, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 77, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 78, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 79, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 80, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 81, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 82, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 83, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 84, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 85, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 86, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 87, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 88, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 89, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 90, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 91, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 92, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 93, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 94, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 95, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 96, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 97, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 98, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 99, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 100, train accuracy = 58.06%, test accuracy = 46.88%\n"
     ]
    }
   ],
   "source": [
    "adam_loss, adam_weight = main(\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x161dfd30>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAKvCAYAAAAbeTy4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUmMMapIkSZLUGIOaJEmSJDXmDyH+RKSSW/XqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14fed908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.plot(momentum_loss, label=\"momentum\")\n",
    "plt.plot(rmsprop_loss, label=\"rmsprop\")\n",
    "plt.plot(adam_loss,label=\"adam\")\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we test to see if it would make a difference when sigmoid cross entropy with logits is used instead of softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(optimizer_fn):\n",
    "\n",
    "    loss_over_time = np.array([])\n",
    "\n",
    "    n_input  = 6      # Number of input nodes: # features and 1 bias\n",
    "    n_hidden = 10      # Number of hidden nodes\n",
    "    n_output = 2      # Number of outputs \n",
    "\n",
    "    weights = init_weights(n_input, n_hidden, n_output)\n",
    "\n",
    "    X = tf.placeholder(\"float32\", shape=[None, n_input])      # 1st parameter is None because to accommodate multiple instanced\n",
    "    y = tf.placeholder(\"float32\", shape=[None, n_output])      # 1st parameter is None because to accommodate multiple instanced\n",
    "    \n",
    "    a2, z2 = do_forwardprop(X, weights['w1'], weights['w2'])\n",
    "\n",
    "    predict  = tf.argmax(a2, axis=1)\n",
    "\n",
    "    loss      = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=z2))\n",
    "    \n",
    "    if optimizer_fn == \"momentum\":\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate=1e-3, momentum=0.9).minimize(loss) \n",
    "    elif optimizer_fn == \"rmsprop\":\n",
    "        optimizer = tf.train.RMSPropOptimizer(learning_rate=1e-3).minimize(loss) \n",
    "    elif optimizer_fn == \"adam\":\n",
    "        optimizer = tf.train.AdamOptimizer().minimize(loss) \n",
    "    elif optimizer_fn == \"gd\":\n",
    "        optimizer = tf.train.GradientDescentOptimizer().minimize(loss)\n",
    "\n",
    "    session = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    session.run(init)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        for i in range(len(X_train)):\n",
    "            _, l = session.run([optimizer, loss], feed_dict={X: X_train[i: i + 1], y: y_train[i: i + 1]})\n",
    "\n",
    "        loss_over_time = np.append(loss_over_time, l)\n",
    "        \n",
    "        train_accuracy = np.mean(np.argmax(y_train, axis=1) == session.run(predict, feed_dict={X: X_train, y: y_train}))\n",
    "        test_accuracy  = np.mean(np.argmax(y_test, axis=1) == session.run(predict, feed_dict={X: X_test, y: y_test}))\n",
    "        print(\"Epoch = %d, train accuracy = %.2f%%, test accuracy = %.2f%%\"\n",
    "              % (epoch + 1, 100. * train_accuracy, 100. * test_accuracy))\n",
    "\n",
    "    weights = session.run(weights)\n",
    "    session.close()\n",
    "    \n",
    "    return loss_over_time, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 2, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 3, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 4, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 5, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 6, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 7, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 8, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 9, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 10, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 11, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 12, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 13, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 14, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 15, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 16, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 17, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 18, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 19, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 20, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 21, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 22, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 23, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 24, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 25, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 26, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 27, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 28, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 29, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 30, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 31, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 32, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 33, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 34, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 35, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 36, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 37, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 38, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 39, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 40, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 41, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 42, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 43, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 44, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 45, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 46, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 47, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 48, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 49, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 50, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 51, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 52, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 53, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 54, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 55, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 56, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 57, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 58, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 59, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 60, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 61, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 62, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 63, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 64, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 65, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 66, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 67, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 68, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 69, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 70, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 71, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 72, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 73, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 74, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 75, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 76, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 77, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 78, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 79, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 80, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 81, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 82, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 83, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 84, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 85, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 86, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 87, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 88, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 89, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 90, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 91, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 92, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 93, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 94, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 95, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 96, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 97, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 98, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 99, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 100, train accuracy = 58.06%, test accuracy = 46.88%\n"
     ]
    }
   ],
   "source": [
    "momentum_loss, momentum_weight = main(\"momentum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 2, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 3, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 4, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 5, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 6, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 7, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 8, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 9, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 10, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 11, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 12, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 13, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 14, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 15, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 16, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 17, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 18, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 19, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 20, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 21, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 22, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 23, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 24, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 25, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 26, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 27, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 28, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 29, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 30, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 31, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 32, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 33, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 34, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 35, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 36, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 37, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 38, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 39, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 40, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 41, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 42, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 43, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 44, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 45, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 46, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 47, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 48, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 49, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 50, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 51, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 52, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 53, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 54, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 55, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 56, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 57, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 58, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 59, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 60, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 61, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 62, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 63, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 64, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 65, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 66, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 67, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 68, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 69, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 70, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 71, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 72, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 73, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 74, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 75, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 76, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 77, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 78, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 79, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 80, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 81, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 82, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 83, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 84, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 85, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 86, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 87, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 88, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 89, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 90, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 91, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 92, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 93, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 94, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 95, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 96, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 97, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 98, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 99, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 100, train accuracy = 58.06%, test accuracy = 46.88%\n"
     ]
    }
   ],
   "source": [
    "rmsprop_loss, rmsprop_weight = main(\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 2, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 3, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 4, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 5, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 6, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 7, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 8, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 9, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 10, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 11, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 12, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 13, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 14, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 15, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 16, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 17, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 18, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 19, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 20, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 21, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 22, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 23, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 24, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 25, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 26, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 27, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 28, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 29, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 30, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 31, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 32, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 33, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 34, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 35, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 36, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 37, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 38, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 39, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 40, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 41, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 42, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 43, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 44, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 45, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 46, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 47, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 48, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 49, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 50, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 51, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 52, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 53, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 54, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 55, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 56, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 57, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 58, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 59, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 60, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 61, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 62, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 63, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 64, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 65, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 66, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 67, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 68, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 69, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 70, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 71, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 72, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 73, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 74, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 75, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 76, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 77, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 78, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 79, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 80, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 81, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 82, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 83, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 84, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 85, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 86, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 87, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 88, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 89, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 90, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 91, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 92, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 93, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 94, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 95, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 96, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 97, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 98, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 99, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 100, train accuracy = 58.06%, test accuracy = 46.88%\n"
     ]
    }
   ],
   "source": [
    "adam_loss, adam_weight = main(\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a 2 layer neural network, all three optimizers, namely momentum, rmsprop, and adam, produced the same test accuracy of 46.88 which did not increase over the epoch iterations. As also shown in the graph above, all three optimizers achieved lower loss very quickly. Based on these results, we can clearly see that a 2 layer neural network is not an appropriate model for classifying our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Summary and Analysis</b>\n",
    "\n",
    "In this sections, we will tabulate all the results and compare them to find the most accurate model for predicting popular songs based on the given audio features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th>Model</th>\n",
    "    <th>Accuracy Score</th> \n",
    "    <th>F1 Score</th>\n",
    "    <th>Recall Score</th>\n",
    "    <th>AUC Score</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Decision Tree</td>\n",
    "    <td>0.5414</td> \n",
    "    <td>0.4</td> \n",
    "    <td>0.5714</td> \n",
    "    <td>0.5210</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Naive Bayes</td>\n",
    "    <td>0.5535</td>\n",
    "    <td>0.375</td> \n",
    "    <td>0.3333</td> \n",
    "    <td>0.5333</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Neural Network</td>\n",
    "    <td>0.4688</td>\n",
    "    <td></td> \n",
    "    <td></td> \n",
    "    <td></td> \n",
    "  </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
