{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Basic Flow</b>\n",
    "- Background of task and data\n",
    "- Summary of technique used\n",
    "- Simple data analysis (show of original data features)\n",
    "- Preprocessing\n",
    "- Feature Extraction (no feature extraction since the features are already given from the second data set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Background and Related Works</b>\n",
    "\n",
    "In recent years, music revenue in the United States has seen substantial growth. In 2017, revenues from recorded music in the United States increased 16.5% at estimated retail value to $8.7 billion, continuing the growth from the previous year. Paid subscriptions from streaming services like Spotify and Apple Music were the biggest growth driver for the music industry in 2017. The revenues from streaming platforms made up 65% of total industry revenues. [1] Online streaming can now be seen as \n",
    "the new norm for accessing and distributing music. Therefore, having a fundamental understanding of what makes a song popular \n",
    "has major implications to musicians and record labels that thrive on stream count and song popularity. \n",
    "\n",
    "The ability to make accurate predictions of song popularity could be achieved through the use of machine learning techniques. \n",
    "\n",
    "Pham, Kyauk and Park used both acoustic features and metadata to create both classification and predictive models, to determine \n",
    "if whether or not the song is popular or in the case of the latter, predict the popularity score. Upon applying SVMs, neural \n",
    "networks and logistic regression for classification, SVM (Gaussian kernel) yielded the highest F1 score. As for regression, \n",
    "they fitted the models using a standard multiple linear regression, and applied feature selection methods to achieve the best \n",
    "coefficient estimates for regression.it was Logistic Lasso regression that yielded the smallest test error. The research \n",
    "concluded that the acoustic features aren’t nearly as predicative as the metadata features. A likely reason for this is that \n",
    "there is a lot of variation in acoustic features within a single song that make it difficult to extract metrics that represent \n",
    "an entire song.[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Objective</b>\n",
    "\n",
    "Determine the popularity of a song based on the given audio features with a value of 1 for popular and 0 for unpopular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Machine Learning Techniques</b>\n",
    "\n",
    "A. Classification:<br>\n",
    "1. Naive Bayes<br>\n",
    "2. SVM<br>\n",
    "3. Decision Tree<br>\n",
    "4. Logistic Regression<br>\n",
    "5. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Description of the Data</b>\n",
    "\n",
    "This research uses data from two Kaggle datasets, namely Spotify’s Worldwide Daily Song Ranking [1] and Top Spotify Tracks of 2017 [2]. The former is a collection of Spotify’s most streamed songs in different regions across the world for each day of 2017. Each row contains a ranking position on a specific day and region. There are roughly 200 entries per day for each region, however be aware that some of Spotify's data was missing in very few occasions. Due to this, the researchers have only focused on the streams (stream count) column for each entry. The latter is a collection of the audio features of the songs found in the Top Spotify Tracks of 2017 playlist in Spotify. Aside from the song title, artist and song url, each song is given values for 13 audio features listed and defined by Spotify API below.\n",
    "<style>\n",
    "table, th, td {\n",
    "    border: 1px solid black;\n",
    "    border-collapse: collapse;\n",
    "    padding: 15px;\n",
    "    text-align: left;\n",
    "}\n",
    "</style>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Feature</th>\n",
    "    <th>Description</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Danceability</td>\n",
    "    <td>Describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Energy</td>\n",
    "    <td>A measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Key</td>\n",
    "    <td>The key the track is in. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Loudness</td>\n",
    "    <td>The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Mode</td>\n",
    "    <td>Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Speechiness</td>\n",
    "    <td>Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Acousticness</td>\n",
    "    <td>A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Instrumentalness</td>\n",
    "    <td>Predicts whether a track contains no vocals. \"Ooh\" and \"aah\" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \"vocal\". The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Liveliness</td>\n",
    "    <td>Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Valence</td>\n",
    "    <td>A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Tempo</td>\n",
    "    <td>The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Duration</td>\n",
    "    <td>The duration of the track in milliseconds.</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Time Signature</td>\n",
    "    <td>An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shown below is the hard-coded table (since file size is extremely large) of the first 5 rows of the Spotify’s Worldwide Daily Song Ranking dataset. For reference, you can view the entire dataset here: https://www.kaggle.com/edumucelli/spotifys-worldwide-daily-song-ranking/data\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Position</th>\n",
    "    <th>Track Name</th>\n",
    "    <th>Artist</th>\n",
    "    <th>Streams</th> \n",
    "    <th>URL</th>\n",
    "    <th>Date</th>\n",
    "    <th>Region</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Reggaetón Lento (Bailemos)</td>\n",
    "    <td>CNCO</td>\n",
    "    <td>19272</td> \n",
    "    <td>https://open.spotify.com/track/3AEZUABDXNtecAOSC1qTfo</td>\n",
    "    <td>2017-01-01</td>\n",
    "    <td>ec</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td>Chantaje</td>\n",
    "    <td>Shakira</td>\n",
    "    <td>19270</td> \n",
    "    <td>https://open.spotify.com/track/6mICuAdrwEjh6Y6lroV2Kg</td>\n",
    "    <td>2017-01-01</td>\n",
    "    <td>ec</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td>Otra Vez (feat. J Balvin)</td>\n",
    "    <td>Zion & Lennox</td>\n",
    "    <td>15761</td> \n",
    "    <td>https://open.spotify.com/track/3QwBODjSEzelZyVjxPOHdq</td>\n",
    "    <td>2017-01-01</td>\n",
    "    <td>ec</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>4</td>\n",
    "    <td>Vente Pa' Ca</td>\n",
    "    <td>Ricky Martin</td>\n",
    "    <td>14954</td> \n",
    "    <td>https://open.spotify.com/track/7DM4BPaS7uofFul3ywMe46</td>\n",
    "    <td>2017-01-01</td>\n",
    "    <td>ec</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5</td>\n",
    "    <td>Safari</td>\n",
    "    <td>J Balvin</td>\n",
    "    <td>14269</td> \n",
    "    <td>https://open.spotify.com/track/6rQSrBHf7HlZjtcMZ4S4bO</td>\n",
    "    <td>2017-01-01</td>\n",
    "    <td>ec</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "# Fix the seed of the random number \n",
    "# generator so that your results will match ours\n",
    "np.random.seed(1)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shown below is the first 5 rows of the Top Spotify Tracks of 2017 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7qiZfU4dY1lWllzX7mPBI</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.931</td>\n",
       "      <td>95.977</td>\n",
       "      <td>233713.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5CtI0qwDJkDQGwXD1H1cL</td>\n",
       "      <td>Despacito - Remix</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.815</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.328</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>0.813</td>\n",
       "      <td>88.931</td>\n",
       "      <td>228827.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4aWmUDTfIPGksMNLV2rQP</td>\n",
       "      <td>Despacito (Featuring Daddy Yankee)</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.786</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.846</td>\n",
       "      <td>177.833</td>\n",
       "      <td>228200.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6RUKPb4LETWmmr3iAEQkt</td>\n",
       "      <td>Something Just Like This</td>\n",
       "      <td>The Chainsmokers</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.635</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-6.769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>0.446</td>\n",
       "      <td>103.019</td>\n",
       "      <td>247160.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3DXncPQOG4VBw3QHh3S81</td>\n",
       "      <td>I'm the One</td>\n",
       "      <td>DJ Khaled</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.668</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-4.284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>0.811</td>\n",
       "      <td>80.924</td>\n",
       "      <td>288600.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                name  \\\n",
       "0  7qiZfU4dY1lWllzX7mPBI                        Shape of You   \n",
       "1  5CtI0qwDJkDQGwXD1H1cL                   Despacito - Remix   \n",
       "2  4aWmUDTfIPGksMNLV2rQP  Despacito (Featuring Daddy Yankee)   \n",
       "3  6RUKPb4LETWmmr3iAEQkt            Something Just Like This   \n",
       "4  3DXncPQOG4VBw3QHh3S81                         I'm the One   \n",
       "\n",
       "            artists  danceability  energy   key  loudness  mode  speechiness  \\\n",
       "0        Ed Sheeran         0.825   0.652   1.0    -3.183   0.0       0.0802   \n",
       "1        Luis Fonsi         0.694   0.815   2.0    -4.328   1.0       0.1200   \n",
       "2        Luis Fonsi         0.660   0.786   2.0    -4.757   1.0       0.1700   \n",
       "3  The Chainsmokers         0.617   0.635  11.0    -6.769   0.0       0.0317   \n",
       "4         DJ Khaled         0.609   0.668   7.0    -4.284   1.0       0.0367   \n",
       "\n",
       "   acousticness  instrumentalness  liveness  valence    tempo  duration_ms  \\\n",
       "0        0.5810          0.000000    0.0931    0.931   95.977     233713.0   \n",
       "1        0.2290          0.000000    0.0924    0.813   88.931     228827.0   \n",
       "2        0.2090          0.000000    0.1120    0.846  177.833     228200.0   \n",
       "3        0.0498          0.000014    0.1640    0.446  103.019     247160.0   \n",
       "4        0.0552          0.000000    0.1670    0.811   80.924     288600.0   \n",
       "\n",
       "   time_signature  \n",
       "0             4.0  \n",
       "1             4.0  \n",
       "2             4.0  \n",
       "3             4.0  \n",
       "4             4.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify = pd.read_csv('featuresdf.csv')\n",
    "spotify.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exploratory Data Analysis</b>\n",
    "\n",
    "Create a distribution plot for the values for each audio feature.<br>\n",
    "Create a feature correlation heat map.<br>\n",
    "See the following examples:<br>\n",
    "https://medium.com/mlreview/spotify-analyzing-and-predicting-songs-58827a0fa42b <br>\n",
    "https://www.kaggle.com/cihanoklap/top-songs-on-spotify-what-makes-them-popular <br>\n",
    "https://www.kaggle.com/nadintamer/what-makes-top-spotify-songs-popular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data Preprocessing</b>\n",
    "\n",
    "Since the research checks the association between the song’s stream count and the song’s features, the researchers have to make sure that the song entry exists in both datasets. The researchers mapped the 100 songs from the Top Spotify Tracks dataset to the entries in the Spotify’s Worldwide Daily Song Ranking dataset and pulled entries with matching song titles. The 256718 entries will serve as the researchers’ working dataset. The dataset would contain duplicate entries, since songs could be on the top 200 in a span of several days in different regions. The researchers get the total stream count per song for the whole year.<br><br>\n",
    "With stream count as the metric of popularity, songs with a stream count higher than mean would be considered as popular (1) and the rest would be labeled as unpopular (0). The song name, stream count and other columns are no longer relevant after preprocessing thus they are removed.\n",
    "\n",
    "Shown below is the final product of the data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveliness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.581000</td>\n",
       "      <td>0.825</td>\n",
       "      <td>233713</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>-3.183</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>95.977</td>\n",
       "      <td>0.931</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.694</td>\n",
       "      <td>228827</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>-4.328</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>88.931</td>\n",
       "      <td>0.813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.904</td>\n",
       "      <td>177000</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0976</td>\n",
       "      <td>-6.842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>150.020</td>\n",
       "      <td>0.400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.726</td>\n",
       "      <td>233902</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.01010</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>-5.043</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>97.985</td>\n",
       "      <td>0.733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002640</td>\n",
       "      <td>0.732</td>\n",
       "      <td>182707</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>-6.366</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2310</td>\n",
       "      <td>155.096</td>\n",
       "      <td>0.401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration  energy  instrumentalness  key  \\\n",
       "0      0.581000         0.825    233713   0.652           0.00000    1   \n",
       "1      0.229000         0.694    228827   0.815           0.00000    2   \n",
       "2      0.000259         0.904    177000   0.611           0.00002    1   \n",
       "3      0.029300         0.726    233902   0.769           0.01010    6   \n",
       "4      0.002640         0.732    182707   0.750           0.00000   11   \n",
       "\n",
       "   liveliness  loudness  mode  speechiness    tempo  valence  popular  \n",
       "0      0.0931    -3.183     0       0.0802   95.977    0.931        1  \n",
       "1      0.0924    -4.328     1       0.1200   88.931    0.813        1  \n",
       "2      0.0976    -6.842     0       0.0888  150.020    0.400        1  \n",
       "3      0.1040    -5.043     1       0.1230   97.985    0.733        1  \n",
       "4      0.1090    -6.366     0       0.2310  155.096    0.401        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify = pd.read_csv('spotify_dataset.csv')\n",
    "spotify.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Feature Selection</b>\n",
    "\n",
    "Choose one of the following:<br>\n",
    "1) Forward Stepwise Selection - Forward selection greedily chooses the best combination of features by starting with an empty subset of features, then incrementally adding a feature to the model that was selected through evaluation of the feature subset through cross-validation. This step is repeated until the generalization error is minimized and the best subset of features is reported.<br>\n",
    "2) Backward Stepwise Selection - Backward stepwise selection works similarly to forward stepwise selection; however, instead of starting with an empty subset of features, it begins by evaluating the use of all features and incrementally removes features until the model is optimized.<br>\n",
    "3) Regularization - Regularization is a shrinkage method that regularizes the coefficient estimates by shrinking the coefficients towards zero. Regularization often improves the fit because reducing coefficient estimates can significantly.<br>\n",
    "\n",
    "For selecting the appropriate features to be used for the machine learning models, we use backward stepwise selection to see wif there are any outlying feature that do not contribute much to the accuracy of the model. We do this by first selecting a random machine learning model which ended up as decision trees because this is the simplest model to construct. Here, we use only one feature out of the thirteen and the resulting accuracy of the test set to the train set is thus tabulated as seen in the table below. Among the features, we will see if there are any feature that has a large variance and remove this feature.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Feature</th>\n",
    "    <th>Accuracy</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Danceability</td>\n",
    "    <td>0.4515</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Energy</td>\n",
    "    <td>0.5005</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Key</td>\n",
    "    <td>0.6167</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Loudness</td>\n",
    "    <td>0.5002</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Mode</td>\n",
    "    <td>0.4859</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Speechiness</td>\n",
    "    <td>0.4831</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Acousticness</td>\n",
    "    <td>0.4204</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Instrumentalness</td>\n",
    "    <td>0.5066</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Liveliness</td>\n",
    "    <td>0.4907</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Valence</td>\n",
    "    <td>0.4290</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Tempo</td>\n",
    "    <td>0.5154</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Duration</td>\n",
    "    <td>0.601</td> \n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "We can see here that most features produced accuracies that are above 0.5. The remaining features that are below 0.5 still had values that are near 0.5 so we opted to also keep these features. As a result, since all features produced decent accuracy, we chose to keep all of them for modelling later on.\n",
    "\n",
    "The code for testing the accuracy for each feature is shown below. Each test is ran for a total of 1000 iterations and the mean of the accuracy for all the iterations are taken as the accuracy for each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Acousticness</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41870833333333335\n"
     ]
    }
   ],
   "source": [
    "spotify = pd.read_csv('spotify_dataset.csv')\n",
    "spotify[\"popular\"] = pd.Categorical(spotify[\"popular\"]).codes\n",
    "\n",
    "X = pd.DataFrame.drop(spotify,labels=['popular','duration','danceability','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "y = pd.DataFrame.drop(spotify,labels=['acousticness','duration','danceability','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X_train,y_train)\n",
    "\n",
    "    predictions = dtc.predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test,predictions))\n",
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Duration</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6035833333333332\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame.drop(spotify,labels=['popular','acousticness','danceability','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "y = pd.DataFrame.drop(spotify,labels=['acousticness','duration','danceability','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y)\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X_train,y_train)\n",
    "    predictions = dtc.predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test,predictions))\n",
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Danceability</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45091666666666663\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame.drop(spotify,labels=['popular','acousticness','duration','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "y = pd.DataFrame.drop(spotify,labels=['acousticness','duration','danceability','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y)\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X_train,y_train)\n",
    "    predictions = dtc.predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test,predictions))\n",
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Energy</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4975\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame.drop(spotify,labels=['popular','acousticness','danceability','duration','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "y = pd.DataFrame.drop(spotify,labels=['acousticness','duration','danceability','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y)\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X_train,y_train)\n",
    "    predictions = dtc.predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test,predictions))\n",
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Instrumentalness</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.501125\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame.drop(spotify,labels=['popular','acousticness','danceability','duration','energy','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "y = pd.DataFrame.drop(spotify,labels=['acousticness','duration','danceability','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y)\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X_train,y_train)\n",
    "    predictions = dtc.predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test,predictions))\n",
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Key</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.620625\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame.drop(spotify,labels=['popular','acousticness','danceability','duration','energy','instrumentalness','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "y = pd.DataFrame.drop(spotify,labels=['acousticness','duration','danceability','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y)\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X_train,y_train)\n",
    "    predictions = dtc.predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test,predictions))\n",
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Liveliness</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48958333333333337\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame.drop(spotify,labels=['popular','acousticness','danceability','duration','energy','instrumentalness','key','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "y = pd.DataFrame.drop(spotify,labels=['acousticness','duration','danceability','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y)\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X_train,y_train)\n",
    "    predictions = dtc.predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test,predictions))\n",
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Loudness</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.505\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame.drop(spotify,labels=['popular','acousticness','danceability','duration','energy','instrumentalness','key','liveliness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "y = pd.DataFrame.drop(spotify,labels=['acousticness','duration','danceability','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y)\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X_train,y_train)\n",
    "    predictions = dtc.predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test,predictions))\n",
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Mode</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4815833333333333\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame.drop(spotify,labels=['popular','acousticness','danceability','duration','energy','instrumentalness','key','liveliness','loudness',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "y = pd.DataFrame.drop(spotify,labels=['acousticness','duration','danceability','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y)\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X_train,y_train)\n",
    "    predictions = dtc.predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test,predictions))\n",
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Speechiness</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48854166666666665\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame.drop(spotify,labels=['popular','acousticness','danceability','duration','energy','instrumentalness','key','liveliness','loudness',\n",
    "                                     'mode','tempo','valence'],axis=1).as_matrix()\n",
    "y = pd.DataFrame.drop(spotify,labels=['acousticness','duration','danceability','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y)\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X_train,y_train)\n",
    "    predictions = dtc.predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test,predictions))\n",
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tempo</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5125833333333333\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame.drop(spotify,labels=['popular','acousticness','danceability','duration','energy','instrumentalness','key','liveliness','loudness',\n",
    "                                     'mode','speechiness','valence'],axis=1).as_matrix()\n",
    "y = pd.DataFrame.drop(spotify,labels=['acousticness','duration','danceability','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y)\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X_train,y_train)\n",
    "    predictions = dtc.predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test,predictions))\n",
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Valence</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4334166666666666\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame.drop(spotify,labels=['popular','acousticness','danceability','duration','energy','instrumentalness','key','liveliness','loudness',\n",
    "                                     'mode','speechiness','tempo'],axis=1).as_matrix()\n",
    "y = pd.DataFrame.drop(spotify,labels=['acousticness','duration','danceability','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y)\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X_train,y_train)\n",
    "    predictions = dtc.predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test,predictions))\n",
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Metrics</b>\n",
    "\n",
    "Precision, recall, and F1 score are used to capture how well our model does in the task of classification. Precision measures the portion of examples that were classified as popular that are truly popular while recall measures the portion of examples that are truly popular that our model classified as popular. F1 score acts as the weighted average between these two values. \n",
    "\n",
    "The AUC is a metric used to evaluate the performance of a binary classifier by taking the area under a curve created by plotting TPR vs. FPR at different probability thresholds. The AUC represents the probability that the classifier ranks a random positive example higher than a random negative one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model Training</b>\n",
    "\n",
    "<b> Decision Tree </b><br>\n",
    "Among the different machine learning classification algorithms, we first implement a model for decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we first import the data from csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveliness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.581000</td>\n",
       "      <td>0.825</td>\n",
       "      <td>233713</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>-3.183</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>95.977</td>\n",
       "      <td>0.931</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.694</td>\n",
       "      <td>228827</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>-4.328</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>88.931</td>\n",
       "      <td>0.813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.904</td>\n",
       "      <td>177000</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0976</td>\n",
       "      <td>-6.842</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>150.020</td>\n",
       "      <td>0.400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.726</td>\n",
       "      <td>233902</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.01010</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>-5.043</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>97.985</td>\n",
       "      <td>0.733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002640</td>\n",
       "      <td>0.732</td>\n",
       "      <td>182707</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>-6.366</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2310</td>\n",
       "      <td>155.096</td>\n",
       "      <td>0.401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration  energy  instrumentalness  key  \\\n",
       "0      0.581000         0.825    233713   0.652           0.00000    1   \n",
       "1      0.229000         0.694    228827   0.815           0.00000    2   \n",
       "2      0.000259         0.904    177000   0.611           0.00002    1   \n",
       "3      0.029300         0.726    233902   0.769           0.01010    6   \n",
       "4      0.002640         0.732    182707   0.750           0.00000   11   \n",
       "\n",
       "   liveliness  loudness  mode  speechiness    tempo  valence  popular  \n",
       "0      0.0931    -3.183     0       0.0802   95.977    0.931        1  \n",
       "1      0.0924    -4.328     1       0.1200   88.931    0.813        1  \n",
       "2      0.0976    -6.842     0       0.0888  150.020    0.400        1  \n",
       "3      0.1040    -5.043     1       0.1230   97.985    0.733        1  \n",
       "4      0.1090    -6.366     0       0.2310  155.096    0.401        1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotify = pd.read_csv('spotify_dataset.csv')\n",
    "spotify[\"popular\"] = pd.Categorical(spotify[\"popular\"]).codes\n",
    "spotify.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we arrange the data into the X and y variables using pandas.DataFrame.drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame.drop(spotify,labels=['popular'],axis=1).as_matrix()\n",
    "y = pd.DataFrame.drop(spotify,labels=['acousticness','duration','danceability','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we separate the data into a train set and a test set to test the accuracy of our model's predictions later on. We then construct our DecisionTreeClassifier model from sklearn and fit our train data in it. Afterward, we make some predictions using the test set and print out the mean of all the accuracies after a total of 1000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5216666666666666\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y)\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X_train,y_train)\n",
    "    predictions = dtc.predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test,predictions))\n",
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Naive Bayes</b>\n",
    "\n",
    "<b>Gaussian Distribution</b><br>\n",
    "Here we use the same X and y from the one we processed in Decision Trees above. We will use GaussianNB since our feature values are continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5565833333333332\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "accuracy = []\n",
    "for i in range(1000):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y)\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train,y_train)\n",
    "    predictions = gnb.predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test,predictions))\n",
    "print(np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted labels for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpopular: 36.0\n",
      "Popular: 34.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Unpopular:\",gnb.class_count_[0])\n",
    "print(\"Popular:\",gnb.class_count_[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The priors the model used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpopular: 0.5142857142857142\n",
      "Popular: 0.4857142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"Unpopular:\",gnb.class_prior_[0])\n",
    "print(\"Popular:\",gnb.class_prior_[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Support Vector Machine</b>\n",
    "\n",
    "Below, we plotted the data points first to see if we have a linearly separable dataset which is not the case as the points are clotted together; therefore, SVM will be a poor model to use on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x17dd1160>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAHVCAYAAADywj0dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAIIliDAAAAEiiGAMAAACSpP8PoJZ0FA0rNAIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17fc76d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "y = np.ravel(y)\n",
    "plt.scatter(X[:,0], X[:,1],c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Neural Networks</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame.drop(spotify,labels=['popular'],axis=1).as_matrix()\n",
    "y = pd.DataFrame.drop(spotify,labels=['acousticness','duration','danceability','energy','instrumentalness','key','liveliness','loudness','mode',\n",
    "                                     'speechiness','tempo','valence'],axis=1).as_matrix()\n",
    "y = np.ravel(y)\n",
    "data = X\n",
    "target = y\n",
    "N, M  = data.shape\n",
    "X = np.ones((N, M + 1))\n",
    "X[:, 1:] = data\n",
    "\n",
    "# Convert into one-hot vectors\n",
    "num_labels = len(np.unique(target))\n",
    "Y = np.eye(num_labels)[target] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (62, 13)\n",
      "y_train shape : (62, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape :\", X_train.shape)\n",
    "print(\"y_train shape :\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_instances = 100 # number of instances (N)\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def init_weights(n_input, n_hidden, n_output):\n",
    "\n",
    "    w1 = tf.random_normal(np.shape(np.zeros((n_input, n_hidden))),stddev=0.1,seed=RANDOM_SEED)\n",
    "    w2 = tf.random_normal(np.shape(np.zeros((n_hidden,n_output))),stddev=0.1,seed=RANDOM_SEED)\n",
    "\n",
    "    weights = {\n",
    "        'w1': tf.Variable(w1),\n",
    "        'w2': tf.Variable(w2)\n",
    "    }\n",
    "\n",
    "    return weights\n",
    "\n",
    "def do_forwardprop(X, W1, W2):\n",
    "\n",
    "    z1 = tf.matmul(X,W1)     # 1st layer score\n",
    "    a1 = tf.nn.sigmoid(z1)     # 1st layer activation\n",
    "    z2 = tf.matmul(z1,W2)      # 2nd layer score\n",
    "    a2 = tf.nn.sigmoid(z2)     # 2nd layer activation\n",
    "\n",
    "    return a2, z2\n",
    "\n",
    "def main(optimizer_fn):\n",
    "\n",
    "    loss_over_time = np.array([])\n",
    "\n",
    "    n_input  = 13      # Number of input nodes: # features and 1 bias\n",
    "    n_hidden = 10      # Number of hidden nodes\n",
    "    n_output = 2      # Number of outputs \n",
    "\n",
    "    weights = init_weights(n_input, n_hidden, n_output)\n",
    "\n",
    "    X = tf.placeholder(\"float32\", shape=[None, n_input])      # 1st parameter is None because to accommodate multiple instanced\n",
    "    y = tf.placeholder(\"float32\", shape=[None, n_output])      # 1st parameter is None because to accommodate multiple instanced\n",
    "    \n",
    "    a2, z2 = do_forwardprop(X, weights['w1'], weights['w2'])\n",
    "\n",
    "    predict  = tf.argmax(a2, axis=1)\n",
    "\n",
    "    loss      = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=z2))\n",
    "    \n",
    "    if optimizer_fn == \"momentum\":\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate=1e-3, momentum=0.9).minimize(loss) \n",
    "    elif optimizer_fn == \"rmsprop\":\n",
    "        optimizer = tf.train.RMSPropOptimizer(learning_rate=1e-3).minimize(loss) \n",
    "    elif optimizer_fn == \"adam\":\n",
    "        optimizer = tf.train.AdamOptimizer().minimize(loss) \n",
    "    elif optimizer_fn == \"gd\":\n",
    "        optimizer = tf.train.GradientDescentOptimizer().minimize(loss)\n",
    "\n",
    "    session = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    session.run(init)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        for i in range(len(X_train)):\n",
    "            _, l = session.run([optimizer, loss], feed_dict={X: X_train[i: i + 1], y: y_train[i: i + 1]})\n",
    "\n",
    "        loss_over_time = np.append(loss_over_time, l)\n",
    "        \n",
    "        train_accuracy = np.mean(np.argmax(y_train, axis=1) == session.run(predict, feed_dict={X: X_train, y: y_train}))\n",
    "        test_accuracy  = np.mean(np.argmax(y_test, axis=1) == session.run(predict, feed_dict={X: X_test, y: y_test}))\n",
    "        print(\"Epoch = %d, train accuracy = %.2f%%, test accuracy = %.2f%%\"\n",
    "              % (epoch + 1, 100. * train_accuracy, 100. * test_accuracy))\n",
    "\n",
    "    weights = session.run(weights)\n",
    "    session.close()\n",
    "    \n",
    "    return loss_over_time, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 2, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 3, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 4, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 5, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 6, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 7, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 8, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 9, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 10, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 11, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 12, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 13, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 14, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 15, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 16, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 17, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 18, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 19, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 20, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 21, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 22, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 23, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 24, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 25, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 26, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 27, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 28, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 29, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 30, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 31, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 32, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 33, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 34, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 35, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 36, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 37, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 38, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 39, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 40, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 41, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 42, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 43, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 44, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 45, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 46, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 47, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 48, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 49, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 50, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 51, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 52, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 53, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 54, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 55, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 56, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 57, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 58, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 59, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 60, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 61, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 62, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 63, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 64, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 65, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 66, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 67, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 68, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 69, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 70, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 71, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 72, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 73, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 74, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 75, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 76, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 77, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 78, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 79, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 80, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 81, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 82, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 83, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 84, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 85, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 86, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 87, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 88, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 89, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 90, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 91, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 92, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 93, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 94, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 95, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 96, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 97, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 98, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 99, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 100, train accuracy = 58.06%, test accuracy = 46.88%\n"
     ]
    }
   ],
   "source": [
    "momentum_loss, momentum_weight = main(\"momentum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 2, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 3, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 4, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 5, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 6, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 7, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 8, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 9, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 10, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 11, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 12, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 13, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 14, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 15, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 16, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 17, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 18, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 19, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 20, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 21, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 22, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 23, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 24, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 25, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 26, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 27, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 28, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 29, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 30, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 31, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 32, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 33, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 34, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 35, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 36, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 37, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 38, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 39, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 40, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 41, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 42, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 43, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 44, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 45, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 46, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 47, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 48, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 49, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 50, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 51, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 52, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 53, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 54, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 55, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 56, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 57, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 58, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 59, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 60, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 61, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 62, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 63, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 64, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 65, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 66, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 67, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 68, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 69, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 70, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 71, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 72, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 73, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 74, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 75, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 76, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 77, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 78, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 79, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 80, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 81, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 82, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 83, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 84, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 85, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 86, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 87, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 88, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 89, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 90, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 91, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 92, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 93, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 94, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 95, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 96, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 97, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 98, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 99, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 100, train accuracy = 58.06%, test accuracy = 46.88%\n"
     ]
    }
   ],
   "source": [
    "rmsprop_loss, rmsprop_weight = main(\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 2, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 3, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 4, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 5, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 6, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 7, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 8, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 9, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 10, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 11, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 12, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 13, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 14, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 15, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 16, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 17, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 18, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 19, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 20, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 21, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 22, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 23, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 24, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 25, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 26, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 27, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 28, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 29, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 30, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 31, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 32, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 33, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 34, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 35, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 36, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 37, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 38, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 39, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 40, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 41, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 42, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 43, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 44, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 45, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 46, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 47, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 48, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 49, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 50, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 51, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 52, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 53, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 54, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 55, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 56, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 57, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 58, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 59, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 60, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 61, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 62, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 63, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 64, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 65, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 66, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 67, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 68, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 69, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 70, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 71, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 72, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 73, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 74, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 75, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 76, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 77, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 78, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 79, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 80, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 81, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 82, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 83, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 84, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 85, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 86, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 87, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 88, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 89, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 90, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 91, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 92, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 93, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 94, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 95, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 96, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 97, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 98, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 99, train accuracy = 58.06%, test accuracy = 46.88%\n",
      "Epoch = 100, train accuracy = 58.06%, test accuracy = 46.88%\n"
     ]
    }
   ],
   "source": [
    "adam_loss, adam_weight = main(\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18a3f3c8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAKvCAYAAAAr9S2ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13cc1fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.plot(momentum_loss, label=\"momentum\")\n",
    "plt.plot(rmsprop_loss, label=\"rmsprop\")\n",
    "plt.plot(adam_loss,label=\"adam\")\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a 2 layer neural network, all three optimizers, namely momentum, rmsprop, and adam, produced the same test accuracy of 46.88 which did not increase over the epoch iterations. As also shown in the graph above, all three optimizers achieved lower loss very quickly. Based on these results, we can clearly see that a 2 layer neural network is not an appropriate model for classifying our dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
